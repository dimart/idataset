{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib, os, sys, zipfile\n",
    "from os.path import dirname\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.core.framework import graph_pb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./mobilenet_ssd_iot2040/graph.pb\", 'rb') as f:\n",
    "    print(\"Reading model from disk...\")\n",
    "    serialized = f.read()\n",
    "\n",
    "tf.reset_default_graph()\n",
    "original_gdef = tf.GraphDef()\n",
    "original_gdef.ParseFromString(serialized)\n",
    "\n",
    "with tf.Graph().as_default() as g:\n",
    "    print(\"Importing model in TF...\")\n",
    "    tf.import_graph_def(original_gdef, name='')\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strip unused subgraphs and save it as another frozen TF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.tools import strip_unused_lib\n",
    "from tensorflow.python.framework import dtypes\n",
    "from tensorflow.python.platform import gfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdef = strip_unused_lib.strip_unused(\n",
    "    input_graph_def = original_gdef,\n",
    "    input_node_names = ['Preprocessor/sub'],\n",
    "    output_node_names = ['concat', 'concat_1'],\n",
    "    placeholder_type_enum = dtypes.float32.as_datatype_enum\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the feature extractor to an output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frozen_model_file = \"./mobilenet_ssd_iot2040/feature_extractor.pb\"\n",
    "with gfile.GFile(frozen_model_file, \"wb\") as f:\n",
    "    f.write(gdef.SerializeToString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a TF model ready to be converted to CoreML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tfcoreml\n",
    "\n",
    "# Call the converter. This may take a while\n",
    "coreml_model = tfcoreml.convert(\n",
    "#     red_bias = -1, \n",
    "#     green_bias = -1, \n",
    "#     blue_bias = -1, \n",
    "#     image_scale = 2.0/255.0,\n",
    "#     image_input_names = \"Preprocessor/sub:0\",\n",
    "    \n",
    "    tf_model_path         = frozen_model_file,\n",
    "    mlmodel_path          = \"./ssd_mobilenet_iot2040.mlmodel\",\n",
    "    input_name_shape_dict = {\"Preprocessor/sub:0\":[1,300,300,3]}, # batch size is 1,\n",
    "    output_feature_names  = ['concat:0', 'concat_1:0']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have converted the model to CoreML, we can test its numerical correctness by comparing it with TensorFlow model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from matplotlib.pyplot import imshow\n",
    "img = PIL.Image.open(\"mobilenet_ssd_iot2040_v1/test_image.jpg\")\n",
    "imshow(np.asarray(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the image - normalize to [-1,1]\n",
    "img = img.resize([300,300], PIL.Image.ANTIALIAS)\n",
    "img_array = np.array(img).astype(np.float32) * 2.0 / 255 - 1\n",
    "batch_img_array = img_array[None,:,:,:]\n",
    "\n",
    "# Evaluate TF\n",
    "tf.reset_default_graph()\n",
    "g = tf.import_graph_def(gdef) # gdef â€“ stripped model\n",
    "\n",
    "tf_input_name = 'Preprocessor/sub:0'\n",
    "tf_output_names = ['concat:0', 'concat_1:0']\n",
    "# concat:0 are the bounding-box encodings of the 1917 anchor boxes\n",
    "# concat_1:0 are the confidence scores of 91 classes of anchor boxes\n",
    "with tf.Session(graph = g) as sess:\n",
    "    image_input_tensor = sess.graph.get_tensor_by_name(\"import/\" + tf_input_name)\n",
    "    tf_output_tensors = [sess.graph.get_tensor_by_name(\"import/\" + output_name)\n",
    "                             for output_name in tf_output_names]\n",
    "    tf_output_values = sess.run(\n",
    "        tf_output_tensors, \n",
    "        feed_dict={image_input_tensor: batch_img_array}\n",
    "    )\n",
    "    tf_box_encodings, tf_scores = tf_output_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf_box_encodings.shape, tf_scores.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_scores[0, 0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we evaluate CoreML model and compare result against TensorFlow model. CoreML uses 5D arrays to represent rank-1 to rank-5 tensors. The 5 axes are in the order of (S,B,C,H,W), where S is sequence length, B is batch size, C is number of channels, H is height and W is width. This data layout is usually different from TensorFlow's default layout, where a rank-4 tensor for convolutional nets usually uses (B,H,W,C) layout. To make a comparison, one of the result should be transposed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import coremltools\n",
    "\n",
    "#  CoreML expects input shape of [1, 1, 3, 300, 300]\n",
    "print(\"Preparing image input for CoreML...\")\n",
    "img_array_coreml = np.transpose(img_array, (2,0,1))[None,None,:,:,:]\n",
    "print(\"Importing model into CoreML...\")\n",
    "mlmodel = coremltools.models.MLModel(\"./ssd_mobilenet_iot2040.mlmodel\")\n",
    "\n",
    "# Pay attention to '__0'. We change ':0' to '__0' to make sure MLModel's \n",
    "# generated Swift/Obj-C code is semantically correct\n",
    "coreml_input_name = tf_input_name.replace(':', '__').replace('/', '__')\n",
    "coreml_output_names = [output_name.replace(':', '__').replace('/', '__') \n",
    "                       for output_name in tf_output_names]\n",
    "coreml_input = {coreml_input_name: img_array_coreml}\n",
    "\n",
    "# When useCPUOnly == True, Relative error should be around 0.001\n",
    "# When useCPUOnly == False on GPU enabled devices, relative errors \n",
    "# are expected to be larger due to utilization of lower-precision arithmetics\n",
    "print(\"Predicting with CoreML...\")\n",
    "coreml_outputs_dict = mlmodel.predict(coreml_input, useCPUOnly=True)\n",
    "coreml_outputs = [coreml_outputs_dict[out_name] for out_name in coreml_output_names]\n",
    "coreml_box_encodings, coreml_scores = coreml_outputs\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(coreml_box_encodings.shape, coreml_scores.shape)\n",
    "print(coreml_scores[0, 0, :, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we compare the differences of two results\n",
    "def max_relative_error(x, y):\n",
    "    den = np.maximum(x, y)\n",
    "    den = np.maximum(den, 1)\n",
    "    rel_err = (np.abs(x-y)) / den\n",
    "    return np.max(rel_err)\n",
    "\n",
    "rel_error_box = max_relative_error(\n",
    "    coreml_box_encodings.squeeze(), \n",
    "    np.transpose(tf_box_encodings.squeeze(), (1,0))\n",
    ")\n",
    "rel_error_score = max_relative_error(\n",
    "    coreml_scores.squeeze(), \n",
    "    np.transpose(tf_scores.squeeze(),(1,0))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Max relative error on box encoding: %f' %(rel_error_box))\n",
    "print('Max relative error on scores: %f' %(rel_error_score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
